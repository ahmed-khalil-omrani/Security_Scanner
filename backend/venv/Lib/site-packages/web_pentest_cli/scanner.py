"""
Core scanning orchestration engine
"""

import logging
from typing import Dict, List, Optional
from datetime import datetime

from .http_client import HTTPClient
from .gather import Gatherer
from .vuln_checks import get_all_checks, VulnerabilityResult
from .utils import get_timestamp, is_valid_url

logger = logging.getLogger(__name__)


class Scanner:
    """
    Main scanning orchestration engine.
    Coordinates reconnaissance and vulnerability checks.
    """

    def __init__(
        self,
        mode: str = 'passive',
        rate_limit: float = 1.0,
        max_depth: int = 2,
        timeout: int = 10,
        user_agent: Optional[str] = None
    ):
        """
        Initialize scanner.

        Args:
            mode: Scanning mode ('passive' or 'active')
            rate_limit: Requests per second
            max_depth: Maximum crawl depth
            timeout: HTTP request timeout
            user_agent: Custom user agent
        """
        self.mode = mode
        self.max_depth = max_depth

        # Initialize HTTP client
        self.http_client = HTTPClient(
            rate_limit=rate_limit,
            timeout=timeout,
            user_agent=user_agent
        )

        # Initialize gatherer
        self.gatherer = Gatherer(self.http_client, max_depth=max_depth)

        # Initialize vulnerability checks
        self.vuln_checks = get_all_checks(self.http_client, mode=mode)

        # Scan metadata
        self.scan_id = None
        self.start_time = None
        self.end_time = None

    def scan(self, target_url: str, consent_info: Optional[Dict] = None) -> Dict:
        """
        Perform complete security scan.

        Args:
            target_url: Target URL to scan
            consent_info: Consent information (required for active mode)

        Returns:
            Scan results dictionary
        """
        if not is_valid_url(target_url):
            raise ValueError(f"Invalid target URL: {target_url}")

        if self.mode == 'active' and not consent_info:
            raise ValueError("Consent information required for active mode scanning")

        self.start_time = datetime.utcnow()
        self.scan_id = f"scan_{int(self.start_time.timestamp())}"

        logger.info(f"Starting scan: {self.scan_id}")
        logger.info(f"Target: {target_url}")
        logger.info(f"Mode: {self.mode}")

        # Initialize results
        results = {
            'scan_id': self.scan_id,
            'target_url': target_url,
            'mode': self.mode,
            'start_time': get_timestamp(),
            'consent_info': consent_info,
            'reconnaissance': {},
            'vulnerabilities': [],
            'statistics': {},
            'checks_performed': []
        }

        try:
            # Phase 1: Reconnaissance
            logger.info("Phase 1: Reconnaissance")
            recon_data = self.gatherer.gather_all(target_url)
            results['reconnaissance'] = {
                'robots_txt': recon_data.get('robots_txt'),
                'sitemap': recon_data.get('sitemap'),
                'discovered_urls_count': len(recon_data.get('discovered_urls', [])),
                'forms_count': len(recon_data.get('forms', [])),
                'input_points_count': len(recon_data.get('input_points', [])),
                'technologies': list(recon_data.get('technologies', []))
            }

            logger.info(f"Discovered: {results['reconnaissance']['discovered_urls_count']} URLs, "
                       f"{results['reconnaissance']['forms_count']} forms")

            # Phase 2: Vulnerability Checks
            logger.info("Phase 2: Vulnerability Scanning")

            # Run checks on main URL
            all_findings = []

            for check in self.vuln_checks:
                logger.info(f"Running check: {check.check_name}")
                results['checks_performed'].append({
                    'check_id': check.check_id,
                    'check_name': check.check_name
                })

                try:
                    findings = check.check(target_url, recon_data)
                    all_findings.extend(findings)
                    logger.info(f"  Found {len(findings)} issues")
                except Exception as e:
                    logger.error(f"Check failed: {check.check_name} - {e}")

            # Also check a sample of discovered URLs
            sample_urls = list(recon_data.get('discovered_urls', []))[:10]

            for url in sample_urls:
                logger.debug(f"Checking discovered URL: {url}")
                for check in self.vuln_checks:
                    try:
                        findings = check.check(url, recon_data)
                        all_findings.extend(findings)
                    except Exception as e:
                        logger.debug(f"Check failed on {url}: {e}")

            # Convert findings to dictionaries
            results['vulnerabilities'] = [f.to_dict() for f in all_findings]

            # Generate statistics
            severity_counts = {'info': 0, 'low': 0, 'medium': 0, 'high': 0, 'critical': 0}
            for vuln in results['vulnerabilities']:
                severity = vuln['severity'].lower()
                if severity in severity_counts:
                    severity_counts[severity] += 1

            self.end_time = datetime.utcnow()
            duration = (self.end_time - self.start_time).total_seconds()

            results['statistics'] = {
                'total_vulnerabilities': len(results['vulnerabilities']),
                'severity_breakdown': severity_counts,
                'http_requests': self.http_client.get_stats()['total_requests'],
                'scan_duration_seconds': duration,
                'urls_scanned': len(sample_urls) + 1
            }

            results['end_time'] = get_timestamp()
            results['status'] = 'completed'

            logger.info(f"Scan completed: {results['statistics']['total_vulnerabilities']} "
                       f"vulnerabilities found in {duration:.2f}s")

        except Exception as e:
            logger.error(f"Scan failed: {e}")
            results['status'] = 'failed'
            results['error'] = str(e)
            results['end_time'] = get_timestamp()

        finally:
            self.http_client.close()

        return results

    def scan_multiple(self, target_urls: List[str], consent_info: Optional[Dict] = None) -> List[Dict]:
        """
        Scan multiple targets.

        Args:
            target_urls: List of target URLs
            consent_info: Consent information

        Returns:
            List of scan results
        """
        results = []

        for i, url in enumerate(target_urls, 1):
            logger.info(f"Scanning target {i}/{len(target_urls)}: {url}")

            try:
                result = self.scan(url, consent_info)
                results.append(result)
            except Exception as e:
                logger.error(f"Failed to scan {url}: {e}")
                results.append({
                    'target_url': url,
                    'status': 'failed',
                    'error': str(e)
                })

        return results
